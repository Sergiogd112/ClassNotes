{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_param_matrices(vocabulary, sentence_terms):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    =======\n",
    "    1. Top 300(or lesser, if vocab is short) most frequent terms(list)\n",
    "    2. co-occurence matrix wrt the most frequent terms(dict)\n",
    "    3. Dict containing Pg of most-frequent terms(dict)\n",
    "    4. nw(no of terms affected) of each term(dict)\n",
    "    \"\"\"\n",
    " \n",
    "    #Figure out top n terms with respect to mere occurences\n",
    "    n = min(300, len(vocabulary))\n",
    "    topterms = list(vocabulary.keys())\n",
    "    topterms.sort(key = lambda x: vocabulary[x], reverse = True)\n",
    "    topterms = topterms[:n]\n",
    " \n",
    "    #nw maps term to the number of terms it 'affects'\n",
    "    #(sum of number of terms in all sentences it\n",
    "    #appears in)\n",
    "    nw = {}\n",
    "    #Co-occurence values are wrt top terms only\n",
    "    co_occur = {}\n",
    "    #Initially, co-occurence matrix is empty\n",
    "    for x in vocabulary:\n",
    "        co_occur[x] = [0 for i in range(len(topterms))]\n",
    " \n",
    "    #Iterate over list of all sentences' vocabulary dictionaries\n",
    "    #Build the co-occurence matrix\n",
    "    for sentence in sentence_terms:\n",
    "        total_terms = sum(list(sentence.values()))\n",
    "        #This list contains the indices of all terms from topterms,\n",
    "        #that are present in this sentence\n",
    "        top_indices = []\n",
    "        #Populate top_indices\n",
    "        top_indices = [topterms.index(x) for x in sentence\n",
    "                       if x in topterms]\n",
    "        #Update nw dict, and co-occurence matrix\n",
    "        for term in sentence:\n",
    "            nw[term] = nw.get(term, 0) + total_terms\n",
    "            for index in top_indices:\n",
    "                co_occur[term][index] += (sentence[term] *\n",
    "                                          sentence[topterms[index]])\n",
    " \n",
    "    #Pg is just nw[term]/total vocabulary of text\n",
    "    Pg = {}\n",
    "    N = sum(list(vocabulary.values()))\n",
    "    for x in topterms:\n",
    "        Pg[x] = float(nw[x])/N\n",
    " \n",
    "    return topterms, co_occur, Pg, nw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_terms(vocabulary, sentence_terms, n=50):\n",
    "    \"\"\"\n",
    "    Returns the top 'n' terms from a block of text, in the form of a list,\n",
    "    from most important to least.\n",
    " \n",
    "    'vocabulary' should be a dict mapping each term to the number\n",
    "    of its occurences in the entire text.\n",
    "    'sentence_terms' should be an iterable of dicts, each denoting the\n",
    "    vocabulary of the corresponding sentence.\n",
    "    \"\"\"\n",
    " \n",
    "    #First compute the matrices\n",
    "    topterms, co_occur, Pg, nw = _get_param_matrices(vocabulary,\n",
    "                                                     sentence_terms)\n",
    " \n",
    "    #This dict will map each term to its weightage with respect to the\n",
    "    #document\n",
    "    result = {}\n",
    " \n",
    "    N = sum(list(vocabulary.values()))\n",
    "    #Iterates over all terms in vocabulary\n",
    "    for term in co_occur:\n",
    "        term = str(term)\n",
    "        org_term = str(term)\n",
    "        for x in Pg:\n",
    "            #expected_cooccur is the expected cooccurence of term with this\n",
    "            #term, based on nw value of this and Pg value of the other\n",
    "            expected_cooccur = nw[term] * Pg[x]\n",
    "            #Result measures the difference(in no of terms) of expected\n",
    "            #cooccurence and  actual cooccurence\n",
    "            result[org_term] = ((co_occur[term][topterms.index(x)] -\n",
    "                                 expected_cooccur)**2/ float(expected_cooccur))\n",
    " \n",
    "    terms = list(result.keys())\n",
    "    terms.sort(key=lambda x: result[x],\n",
    "               reverse=True)\n",
    " \n",
    "    return terms[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from networkx import Graph\n",
    " \n",
    "def build_mind_map(model, stemmer, root, nodes, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Returns the Mind-Map in the form of a NetworkX Graph instance.\n",
    " \n",
    "    'model' should be an instance of gensim.models.Word2Vec\n",
    "    'nodes' should be a list of terms, included in the vocabulary of\n",
    "    'model'.\n",
    "    'root' should be the node that is to be used as the root of the Mind\n",
    "    Map graph.\n",
    "    'stemmer' should be an instance of StemmingHelper.\n",
    "    \"\"\"\n",
    " \n",
    "    #This will be the Mind-Map\n",
    "    g = Graph()\n",
    " \n",
    "    #Ensure that the every node is in the vocabulary of the Word2Vec\n",
    "    #model, and that the root itself is included in the given nodes\n",
    "    for node in nodes:\n",
    "        if node not in model.vocab:\n",
    "            raise ValueError(node + \" not in model's vocabulary\")\n",
    "    if root not in nodes:\n",
    "        raise ValueError(\"root not in nodes\")\n",
    " \n",
    "    ##Containers for algorithm run\n",
    "    #Initially, all nodes are unvisited\n",
    "    unvisited_nodes = set(nodes)\n",
    "    #Initially, no nodes are visited\n",
    "    visited_nodes = set([])\n",
    "    #The following will map visited node to its contextual vector\n",
    "    visited_node_vectors = {}\n",
    "    #Thw following will map unvisited nodes to (closest_distance, parent)\n",
    "    #parent will obviously be a visited node\n",
    "    node_distances = {}\n",
    " \n",
    "    #Initialization with respect to root\n",
    "    current_node = root\n",
    "    visited_node_vectors[root] = model[root]\n",
    "    unvisited_nodes.remove(root)\n",
    "    visited_nodes.add(root)\n",
    " \n",
    "    #Build the Mind-Map in n-1 iterations\n",
    "    for i in range(1, len(nodes)):\n",
    "        #For every unvisited node 'x'\n",
    "        for x in unvisited_nodes:\n",
    "            #Compute contextual distance between current node and x\n",
    "            dist_from_current = cosine(visited_node_vectors[current_node],\n",
    "                                       model[x])\n",
    "            #Get the least contextual distance to x found until now\n",
    "            distance = node_distances.get(x, (100, ''))\n",
    "            #If current node provides a shorter path to x, update x's\n",
    "            #distance and parent information\n",
    "            if distance[0] > dist_from_current:\n",
    "                node_distances[x] = (dist_from_current, current_node)\n",
    " \n",
    "        #Choose next 'current' as that unvisited node, which has the\n",
    "        #lowest contextual distance from any of the visited nodes\n",
    "        next_node = min(unvisited_nodes,\n",
    "                        key=lambda x: node_distances[x][0])\n",
    " \n",
    "        ##Update all containers\n",
    "        parent = node_distances[next_node][1]\n",
    "        del node_distances[next_node]\n",
    "        next_node_vect = ((1 - alpha)*model[next_node] +\n",
    "                          alpha*visited_node_vectors[parent])\n",
    "        visited_node_vectors[next_node] = next_node_vect\n",
    "        unvisited_nodes.remove(next_node)\n",
    "        visited_nodes.add(next_node)\n",
    " \n",
    "        #Add the link between newly selected node and its parent(from the\n",
    "        #visited nodes) to the NetworkX Graph instance\n",
    "        g.add_edge(stemmer.original_form(parent).capitalize(),\n",
    "                   stemmer.original_form(next_node).capitalize())\n",
    " \n",
    "        #The new node becomes the current node for the next iteration\n",
    "        current_node = next_node\n",
    " \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
